{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import chess\n",
    "import chess.pgn\n",
    "import chess.engine\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgnGames = list(pathlib.Path('test_pgns').glob('*.pgn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General space saving algorithms that are often used in chess programming sites\n",
    "\n",
    "def board_to_arr(board: chess.Board):\n",
    "    black, white = board.occupied_co\n",
    "\n",
    "    bitboards = np.array([\n",
    "        black & board.pawns,\n",
    "        black & board.knights,\n",
    "        black & board.bishops,\n",
    "        black & board.rooks,\n",
    "        black & board.queens,\n",
    "        black & board.kings,\n",
    "        white & board.pawns,\n",
    "        white & board.knights,\n",
    "        white & board.bishops,\n",
    "        white & board.rooks,\n",
    "        white & board.queens,\n",
    "        white & board.kings,\n",
    "    ], dtype=np.uint64)\n",
    "\n",
    "    return bitboards\n",
    "\n",
    "def bitboards_to_array(bb: np.ndarray) -> np.ndarray:\n",
    "    bb = np.asarray(bb, dtype=np.uint64)[:, np.newaxis]\n",
    "    s = 8 * np.arange(7, -1, -1, dtype=np.uint64)\n",
    "    b = (bb >> s).astype(np.uint8)\n",
    "    b = np.unpackbits(b, bitorder=\"little\")\n",
    "    return b.reshape(-1, 8, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = chess.engine.SimpleEngine.popen_uci(\"engines/stockfish-macos-x86-64-bmi2\")\n",
    "\n",
    "def convert_to_winrate(acpl):\n",
    "    \n",
    "    return (50 + 50 * (2 / (1 + np.exp(-0.00368208 * acpl)) - 1)) * 0.01\n",
    "\n",
    "def evaluate_game(game, think_time=0.1, verbose=False):\n",
    "    \n",
    "    single_game = []\n",
    "    evaluations = []\n",
    "    \n",
    "    board = game.board()\n",
    "\n",
    "    for move in game.mainline_moves():\n",
    "    \n",
    "        # Evaluate the current position \n",
    "        result = engine.analyse(board, chess.engine.Limit(time=think_time))\n",
    "        \n",
    "        if result['score'].turn: \n",
    "            try:\n",
    "                objective_eval = result['score'].relative.cp\n",
    "                evaluations.append(convert_to_winrate(objective_eval))\n",
    "            except:\n",
    "                if result['score'].relative.moves > 0:\n",
    "                    evaluations.append(1)\n",
    "                else:\n",
    "                    evaluations.append(0)\n",
    "        else:\n",
    "            try:\n",
    "                objective_eval = result['score'].relative.cp * -1\n",
    "                evaluations.append(convert_to_winrate(objective_eval))\n",
    "            except:\n",
    "                if result['score'].relative.moves < 0:\n",
    "                    evaluations.append(1)\n",
    "                else:\n",
    "                    evaluations.append(0)       \n",
    "        \n",
    "        # Push the game state to new\n",
    "        board.push_uci(move.uci())\n",
    "        single_game.append(board_to_arr(board))\n",
    "    \n",
    "    # Evaluate final position once more to find accuracy of last move\n",
    "    result = engine.analyse(board, chess.engine.Limit(time=think_time))\n",
    "    evaluations.append(convert_to_winrate(objective_eval))\n",
    "    if verbose:\n",
    "        print(evaluations)\n",
    "    \n",
    "    winrate_diff = [abs(x - evaluations[i - 1]) for i, x in enumerate(evaluations)][1:]\n",
    "\n",
    "    return single_game, winrate_diff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 games analyzed, dataset size 31\n",
      "2 games analyzed, dataset size 41\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "4 games analyzed, dataset size 61\n",
      "5 games analyzed, dataset size 63\n",
      "6 games analyzed, dataset size 118\n",
      "7 games analyzed, dataset size 199\n",
      "8 games analyzed, dataset size 280\n",
      "9 games analyzed, dataset size 314\n",
      "10 games analyzed, dataset size 365\n",
      "11 games analyzed, dataset size 431\n",
      "12 games analyzed, dataset size 484\n",
      "13 games analyzed, dataset size 529\n",
      "14 games analyzed, dataset size 594\n",
      "15 games analyzed, dataset size 637\n",
      "16 games analyzed, dataset size 760\n",
      "17 games analyzed, dataset size 886\n",
      "18 games analyzed, dataset size 957\n",
      "19 games analyzed, dataset size 1076\n",
      "20 games analyzed, dataset size 1146\n",
      "21 games analyzed, dataset size 1174\n",
      "22 games analyzed, dataset size 1209\n",
      "23 games analyzed, dataset size 1250\n",
      "24 games analyzed, dataset size 1290\n",
      "25 games analyzed, dataset size 1326\n",
      "26 games analyzed, dataset size 1371\n",
      "27 games analyzed, dataset size 1436\n",
      "28 games analyzed, dataset size 1492\n",
      "29 games analyzed, dataset size 1544\n",
      "30 games analyzed, dataset size 1581\n",
      "31 games analyzed, dataset size 1610\n",
      "32 games analyzed, dataset size 1714\n",
      "33 games analyzed, dataset size 1833\n",
      "34 games analyzed, dataset size 1921\n",
      "35 games analyzed, dataset size 1975\n",
      "36 games analyzed, dataset size 2028\n",
      "37 games analyzed, dataset size 2086\n",
      "38 games analyzed, dataset size 2169\n",
      "39 games analyzed, dataset size 2170\n",
      "40 games analyzed, dataset size 2240\n",
      "41 games analyzed, dataset size 2279\n",
      "42 games analyzed, dataset size 2413\n",
      "43 games analyzed, dataset size 2475\n",
      "44 games analyzed, dataset size 2567\n",
      "45 games analyzed, dataset size 2670\n",
      "46 games analyzed, dataset size 2679\n",
      "47 games analyzed, dataset size 2800\n",
      "48 games analyzed, dataset size 2853\n",
      "49 games analyzed, dataset size 2882\n",
      "50 games analyzed, dataset size 2931\n",
      "51 games analyzed, dataset size 2986\n",
      "52 games analyzed, dataset size 3029\n",
      "53 games analyzed, dataset size 3093\n",
      "54 games analyzed, dataset size 3181\n",
      "55 games analyzed, dataset size 3222\n",
      "56 games analyzed, dataset size 3323\n",
      "57 games analyzed, dataset size 3356\n",
      "58 games analyzed, dataset size 3414\n",
      "59 games analyzed, dataset size 3446\n",
      "60 games analyzed, dataset size 3495\n",
      "61 games analyzed, dataset size 3555\n",
      "62 games analyzed, dataset size 3600\n",
      "63 games analyzed, dataset size 3698\n",
      "64 games analyzed, dataset size 3733\n",
      "65 games analyzed, dataset size 3753\n",
      "66 games analyzed, dataset size 3846\n",
      "67 games analyzed, dataset size 3898\n",
      "68 games analyzed, dataset size 3978\n",
      "69 games analyzed, dataset size 3979\n",
      "70 games analyzed, dataset size 4061\n",
      "71 games analyzed, dataset size 4085\n",
      "72 games analyzed, dataset size 4116\n",
      "73 games analyzed, dataset size 4179\n",
      "74 games analyzed, dataset size 4309\n",
      "75 games analyzed, dataset size 4331\n",
      "76 games analyzed, dataset size 4332\n",
      "77 games analyzed, dataset size 4403\n",
      "78 games analyzed, dataset size 4448\n",
      "79 games analyzed, dataset size 4465\n",
      "80 games analyzed, dataset size 4502\n",
      "81 games analyzed, dataset size 4572\n",
      "82 games analyzed, dataset size 4612\n",
      "83 games analyzed, dataset size 4720\n",
      "84 games analyzed, dataset size 4789\n",
      "85 games analyzed, dataset size 4910\n",
      "86 games analyzed, dataset size 4967\n",
      "87 games analyzed, dataset size 5007\n",
      "88 games analyzed, dataset size 5062\n",
      "89 games analyzed, dataset size 5166\n",
      "90 games analyzed, dataset size 5216\n",
      "91 games analyzed, dataset size 5270\n",
      "92 games analyzed, dataset size 5347\n",
      "93 games analyzed, dataset size 5441\n",
      "94 games analyzed, dataset size 5486\n",
      "95 games analyzed, dataset size 5614\n",
      "96 games analyzed, dataset size 5693\n",
      "97 games analyzed, dataset size 5788\n",
      "98 games analyzed, dataset size 5862\n",
      "99 games analyzed, dataset size 6002\n",
      "100 games analyzed, dataset size 6077\n",
      "101 games analyzed, dataset size 6138\n",
      "102 games analyzed, dataset size 6166\n",
      "103 games analyzed, dataset size 6263\n",
      "104 games analyzed, dataset size 6335\n",
      "105 games analyzed, dataset size 6387\n",
      "106 games analyzed, dataset size 6492\n",
      "107 games analyzed, dataset size 6540\n",
      "108 games analyzed, dataset size 6589\n",
      "109 games analyzed, dataset size 6618\n",
      "110 games analyzed, dataset size 6717\n",
      "111 games analyzed, dataset size 6785\n",
      "112 games analyzed, dataset size 6902\n",
      "113 games analyzed, dataset size 7098\n",
      "114 games analyzed, dataset size 7209\n",
      "115 games analyzed, dataset size 7322\n",
      "116 games analyzed, dataset size 7397\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "118 games analyzed, dataset size 7475\n",
      "119 games analyzed, dataset size 7553\n",
      "120 games analyzed, dataset size 7587\n",
      "121 games analyzed, dataset size 7645\n",
      "122 games analyzed, dataset size 7761\n",
      "123 games analyzed, dataset size 7856\n",
      "124 games analyzed, dataset size 7942\n",
      "125 games analyzed, dataset size 8014\n",
      "126 games analyzed, dataset size 8045\n",
      "127 games analyzed, dataset size 8126\n",
      "128 games analyzed, dataset size 8194\n",
      "129 games analyzed, dataset size 8292\n",
      "130 games analyzed, dataset size 8364\n",
      "131 games analyzed, dataset size 8463\n",
      "132 games analyzed, dataset size 8540\n",
      "133 games analyzed, dataset size 8619\n",
      "134 games analyzed, dataset size 8702\n",
      "135 games analyzed, dataset size 8781\n",
      "136 games analyzed, dataset size 8823\n",
      "137 games analyzed, dataset size 8872\n",
      "138 games analyzed, dataset size 9000\n",
      "139 games analyzed, dataset size 9045\n",
      "140 games analyzed, dataset size 9163\n",
      "141 games analyzed, dataset size 9256\n",
      "142 games analyzed, dataset size 9315\n",
      "143 games analyzed, dataset size 9415\n",
      "144 games analyzed, dataset size 9517\n",
      "145 games analyzed, dataset size 9588\n",
      "146 games analyzed, dataset size 9678\n",
      "147 games analyzed, dataset size 9729\n",
      "148 games analyzed, dataset size 9769\n",
      "149 games analyzed, dataset size 9840\n",
      "150 games analyzed, dataset size 9926\n",
      "151 games analyzed, dataset size 10002\n",
      "152 games analyzed, dataset size 10080\n",
      "153 games analyzed, dataset size 10152\n",
      "154 games analyzed, dataset size 10195\n",
      "155 games analyzed, dataset size 10225\n",
      "156 games analyzed, dataset size 10262\n",
      "157 games analyzed, dataset size 10351\n",
      "158 games analyzed, dataset size 10436\n",
      "159 games analyzed, dataset size 10489\n",
      "160 games analyzed, dataset size 10490\n",
      "161 games analyzed, dataset size 10606\n",
      "162 games analyzed, dataset size 10651\n",
      "163 games analyzed, dataset size 10727\n",
      "164 games analyzed, dataset size 10791\n",
      "165 games analyzed, dataset size 10871\n",
      "166 games analyzed, dataset size 10891\n",
      "167 games analyzed, dataset size 11019\n",
      "168 games analyzed, dataset size 11136\n",
      "169 games analyzed, dataset size 11216\n",
      "170 games analyzed, dataset size 11365\n",
      "171 games analyzed, dataset size 11416\n",
      "172 games analyzed, dataset size 11461\n",
      "173 games analyzed, dataset size 11618\n",
      "174 games analyzed, dataset size 11701\n",
      "175 games analyzed, dataset size 11808\n",
      "176 games analyzed, dataset size 11866\n",
      "177 games analyzed, dataset size 11929\n",
      "178 games analyzed, dataset size 11997\n",
      "179 games analyzed, dataset size 12132\n",
      "180 games analyzed, dataset size 12189\n",
      "181 games analyzed, dataset size 12296\n",
      "182 games analyzed, dataset size 12336\n",
      "183 games analyzed, dataset size 12495\n",
      "184 games analyzed, dataset size 12559\n",
      "185 games analyzed, dataset size 12638\n",
      "186 games analyzed, dataset size 12700\n",
      "187 games analyzed, dataset size 12751\n",
      "188 games analyzed, dataset size 12804\n",
      "189 games analyzed, dataset size 12855\n",
      "190 games analyzed, dataset size 12917\n",
      "191 games analyzed, dataset size 12989\n",
      "192 games analyzed, dataset size 13076\n",
      "193 games analyzed, dataset size 13139\n",
      "194 games analyzed, dataset size 13176\n",
      "195 games analyzed, dataset size 13205\n",
      "196 games analyzed, dataset size 13268\n",
      "197 games analyzed, dataset size 13269\n",
      "198 games analyzed, dataset size 13392\n",
      "199 games analyzed, dataset size 13439\n",
      "200 games analyzed, dataset size 13535\n",
      "201 games analyzed, dataset size 13621\n",
      "202 games analyzed, dataset size 13727\n",
      "203 games analyzed, dataset size 13787\n",
      "204 games analyzed, dataset size 13870\n",
      "205 games analyzed, dataset size 13975\n",
      "206 games analyzed, dataset size 14089\n",
      "207 games analyzed, dataset size 14195\n",
      "208 games analyzed, dataset size 14208\n",
      "209 games analyzed, dataset size 14295\n",
      "210 games analyzed, dataset size 14339\n",
      "211 games analyzed, dataset size 14390\n",
      "212 games analyzed, dataset size 14468\n",
      "213 games analyzed, dataset size 14508\n",
      "214 games analyzed, dataset size 14555\n",
      "215 games analyzed, dataset size 14609\n",
      "216 games analyzed, dataset size 14647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 games analyzed, dataset size 14727\n",
      "218 games analyzed, dataset size 14785\n",
      "219 games analyzed, dataset size 14894\n",
      "220 games analyzed, dataset size 14940\n",
      "221 games analyzed, dataset size 15056\n",
      "222 games analyzed, dataset size 15123\n",
      "223 games analyzed, dataset size 15162\n",
      "224 games analyzed, dataset size 15271\n",
      "225 games analyzed, dataset size 15333\n",
      "226 games analyzed, dataset size 15405\n",
      "227 games analyzed, dataset size 15489\n",
      "228 games analyzed, dataset size 15613\n",
      "229 games analyzed, dataset size 15734\n",
      "230 games analyzed, dataset size 15772\n",
      "231 games analyzed, dataset size 15824\n",
      "232 games analyzed, dataset size 15883\n",
      "233 games analyzed, dataset size 15939\n",
      "234 games analyzed, dataset size 16001\n",
      "235 games analyzed, dataset size 16028\n",
      "236 games analyzed, dataset size 16080\n",
      "237 games analyzed, dataset size 16145\n",
      "238 games analyzed, dataset size 16209\n",
      "239 games analyzed, dataset size 16253\n",
      "240 games analyzed, dataset size 16311\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "242 games analyzed, dataset size 16367\n",
      "243 games analyzed, dataset size 16426\n",
      "244 games analyzed, dataset size 16501\n",
      "245 games analyzed, dataset size 16607\n",
      "246 games analyzed, dataset size 16690\n",
      "247 games analyzed, dataset size 16746\n",
      "248 games analyzed, dataset size 16855\n",
      "249 games analyzed, dataset size 16922\n",
      "250 games analyzed, dataset size 16972\n",
      "251 games analyzed, dataset size 17052\n",
      "252 games analyzed, dataset size 17157\n",
      "253 games analyzed, dataset size 17248\n",
      "254 games analyzed, dataset size 17305\n",
      "255 games analyzed, dataset size 17425\n",
      "256 games analyzed, dataset size 17456\n",
      "257 games analyzed, dataset size 17503\n",
      "258 games analyzed, dataset size 17571\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "260 games analyzed, dataset size 17639\n",
      "261 games analyzed, dataset size 17676\n",
      "262 games analyzed, dataset size 17724\n",
      "263 games analyzed, dataset size 17799\n",
      "264 games analyzed, dataset size 17850\n",
      "265 games analyzed, dataset size 17900\n",
      "266 games analyzed, dataset size 17966\n",
      "267 games analyzed, dataset size 18043\n",
      "268 games analyzed, dataset size 18139\n",
      "269 games analyzed, dataset size 18222\n",
      "270 games analyzed, dataset size 18303\n",
      "271 games analyzed, dataset size 18366\n",
      "272 games analyzed, dataset size 18419\n",
      "273 games analyzed, dataset size 18486\n",
      "274 games analyzed, dataset size 18617\n",
      "275 games analyzed, dataset size 18698\n",
      "276 games analyzed, dataset size 18753\n",
      "277 games analyzed, dataset size 18866\n",
      "278 games analyzed, dataset size 18955\n",
      "279 games analyzed, dataset size 19016\n",
      "280 games analyzed, dataset size 19150\n",
      "281 games analyzed, dataset size 19189\n",
      "282 games analyzed, dataset size 19248\n",
      "283 games analyzed, dataset size 19278\n",
      "284 games analyzed, dataset size 19326\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "286 games analyzed, dataset size 19386\n",
      "287 games analyzed, dataset size 19419\n",
      "288 games analyzed, dataset size 19521\n",
      "289 games analyzed, dataset size 19585\n",
      "290 games analyzed, dataset size 19716\n",
      "291 games analyzed, dataset size 19757\n",
      "292 games analyzed, dataset size 19809\n",
      "293 games analyzed, dataset size 19875\n",
      "294 games analyzed, dataset size 19929\n",
      "295 games analyzed, dataset size 20017\n",
      "296 games analyzed, dataset size 20136\n",
      "297 games analyzed, dataset size 20227\n",
      "298 games analyzed, dataset size 20302\n",
      "299 games analyzed, dataset size 20378\n",
      "300 games analyzed, dataset size 20411\n",
      "301 games analyzed, dataset size 20473\n",
      "302 games analyzed, dataset size 20545\n",
      "303 games analyzed, dataset size 20615\n",
      "304 games analyzed, dataset size 20673\n",
      "305 games analyzed, dataset size 20749\n",
      "306 games analyzed, dataset size 20823\n",
      "307 games analyzed, dataset size 20911\n",
      "308 games analyzed, dataset size 20992\n",
      "309 games analyzed, dataset size 21063\n",
      "310 games analyzed, dataset size 21098\n",
      "311 games analyzed, dataset size 21180\n",
      "312 games analyzed, dataset size 21266\n",
      "313 games analyzed, dataset size 21311\n",
      "314 games analyzed, dataset size 21369\n",
      "315 games analyzed, dataset size 21409\n",
      "316 games analyzed, dataset size 21445\n",
      "317 games analyzed, dataset size 21501\n",
      "318 games analyzed, dataset size 21571\n",
      "319 games analyzed, dataset size 21629\n",
      "320 games analyzed, dataset size 21691\n",
      "321 games analyzed, dataset size 21735\n",
      "322 games analyzed, dataset size 21788\n",
      "323 games analyzed, dataset size 21882\n",
      "324 games analyzed, dataset size 21951\n",
      "325 games analyzed, dataset size 22040\n",
      "326 games analyzed, dataset size 22130\n",
      "327 games analyzed, dataset size 22192\n",
      "328 games analyzed, dataset size 22252\n",
      "329 games analyzed, dataset size 22330\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "331 games analyzed, dataset size 22442\n",
      "332 games analyzed, dataset size 22468\n",
      "333 games analyzed, dataset size 22532\n",
      "334 games analyzed, dataset size 22575\n",
      "335 games analyzed, dataset size 22676\n",
      "336 games analyzed, dataset size 22798\n",
      "337 games analyzed, dataset size 22876\n",
      "338 games analyzed, dataset size 23019\n",
      "339 games analyzed, dataset size 23079\n",
      "340 games analyzed, dataset size 23141\n",
      "341 games analyzed, dataset size 23215\n",
      "342 games analyzed, dataset size 23242\n",
      "343 games analyzed, dataset size 23328\n",
      "344 games analyzed, dataset size 23444\n",
      "345 games analyzed, dataset size 23466\n",
      "346 games analyzed, dataset size 23503\n",
      "347 games analyzed, dataset size 23588\n",
      "348 games analyzed, dataset size 23708\n",
      "349 games analyzed, dataset size 23794\n",
      "350 games analyzed, dataset size 23855\n",
      "351 games analyzed, dataset size 23965\n",
      "352 games analyzed, dataset size 24113\n",
      "353 games analyzed, dataset size 24143\n",
      "354 games analyzed, dataset size 24198\n",
      "355 games analyzed, dataset size 24282\n",
      "356 games analyzed, dataset size 24331\n",
      "357 games analyzed, dataset size 24481\n",
      "358 games analyzed, dataset size 24575\n",
      "359 games analyzed, dataset size 24617\n",
      "360 games analyzed, dataset size 24704\n",
      "361 games analyzed, dataset size 24743\n",
      "362 games analyzed, dataset size 24830\n",
      "363 games analyzed, dataset size 24900\n",
      "364 games analyzed, dataset size 25047\n",
      "365 games analyzed, dataset size 25175\n",
      "366 games analyzed, dataset size 25260\n",
      "367 games analyzed, dataset size 25309\n",
      "368 games analyzed, dataset size 25317\n",
      "369 games analyzed, dataset size 25403\n",
      "370 games analyzed, dataset size 25515\n",
      "371 games analyzed, dataset size 25587\n",
      "372 games analyzed, dataset size 25689\n",
      "373 games analyzed, dataset size 25773\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "375 games analyzed, dataset size 25828\n",
      "376 games analyzed, dataset size 25924\n",
      "377 games analyzed, dataset size 26009\n",
      "378 games analyzed, dataset size 26085\n",
      "379 games analyzed, dataset size 26160\n",
      "380 games analyzed, dataset size 26262\n",
      "381 games analyzed, dataset size 26342\n",
      "382 games analyzed, dataset size 26343\n",
      "383 games analyzed, dataset size 26414\n",
      "384 games analyzed, dataset size 26529\n",
      "385 games analyzed, dataset size 26677\n",
      "386 games analyzed, dataset size 26764\n",
      "387 games analyzed, dataset size 26874\n",
      "388 games analyzed, dataset size 26996\n",
      "389 games analyzed, dataset size 27050\n",
      "390 games analyzed, dataset size 27153\n",
      "391 games analyzed, dataset size 27176\n",
      "392 games analyzed, dataset size 27268\n",
      "393 games analyzed, dataset size 27299\n",
      "394 games analyzed, dataset size 27360\n",
      "395 games analyzed, dataset size 27427\n",
      "396 games analyzed, dataset size 27482\n",
      "397 games analyzed, dataset size 27546\n",
      "398 games analyzed, dataset size 27613\n",
      "399 games analyzed, dataset size 27672\n",
      "400 games analyzed, dataset size 27786\n",
      "401 games analyzed, dataset size 27860\n",
      "402 games analyzed, dataset size 27889\n",
      "403 games analyzed, dataset size 28000\n",
      "404 games analyzed, dataset size 28115\n",
      "405 games analyzed, dataset size 28196\n",
      "406 games analyzed, dataset size 28292\n",
      "407 games analyzed, dataset size 28409\n",
      "408 games analyzed, dataset size 28462\n",
      "409 games analyzed, dataset size 28562\n",
      "410 games analyzed, dataset size 28617\n",
      "411 games analyzed, dataset size 28720\n",
      "412 games analyzed, dataset size 28762\n",
      "413 games analyzed, dataset size 28817\n",
      "414 games analyzed, dataset size 28899\n",
      "415 games analyzed, dataset size 29078\n",
      "416 games analyzed, dataset size 29122\n",
      "417 games analyzed, dataset size 29179\n",
      "418 games analyzed, dataset size 29249\n",
      "419 games analyzed, dataset size 29318\n",
      "420 games analyzed, dataset size 29380\n",
      "421 games analyzed, dataset size 29432\n",
      "422 games analyzed, dataset size 29488\n",
      "423 games analyzed, dataset size 29546\n",
      "424 games analyzed, dataset size 29600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425 games analyzed, dataset size 29628\n",
      "426 games analyzed, dataset size 29669\n",
      "427 games analyzed, dataset size 29708\n",
      "428 games analyzed, dataset size 29806\n",
      "429 games analyzed, dataset size 29884\n",
      "430 games analyzed, dataset size 29944\n",
      "431 games analyzed, dataset size 30063\n",
      "432 games analyzed, dataset size 30138\n",
      "433 games analyzed, dataset size 30225\n",
      "434 games analyzed, dataset size 30341\n",
      "435 games analyzed, dataset size 30389\n",
      "436 games analyzed, dataset size 30462\n",
      "437 games analyzed, dataset size 30521\n",
      "438 games analyzed, dataset size 30596\n",
      "439 games analyzed, dataset size 30701\n",
      "440 games analyzed, dataset size 30764\n",
      "441 games analyzed, dataset size 30862\n",
      "442 games analyzed, dataset size 30899\n",
      "443 games analyzed, dataset size 30974\n",
      "444 games analyzed, dataset size 31037\n",
      "445 games analyzed, dataset size 31159\n",
      "446 games analyzed, dataset size 31224\n",
      "447 games analyzed, dataset size 31247\n",
      "448 games analyzed, dataset size 31318\n",
      "449 games analyzed, dataset size 31369\n",
      "450 games analyzed, dataset size 31444\n",
      "451 games analyzed, dataset size 31497\n",
      "452 games analyzed, dataset size 31606\n",
      "453 games analyzed, dataset size 31656\n",
      "454 games analyzed, dataset size 31740\n",
      "455 games analyzed, dataset size 31765\n",
      "456 games analyzed, dataset size 31870\n",
      "457 games analyzed, dataset size 31909\n",
      "458 games analyzed, dataset size 31966\n",
      "459 games analyzed, dataset size 32031\n",
      "460 games analyzed, dataset size 32084\n",
      "461 games analyzed, dataset size 32136\n",
      "462 games analyzed, dataset size 32241\n",
      "463 games analyzed, dataset size 32298\n",
      "464 games analyzed, dataset size 32381\n",
      "465 games analyzed, dataset size 32437\n",
      "466 games analyzed, dataset size 32492\n",
      "467 games analyzed, dataset size 32555\n",
      "468 games analyzed, dataset size 32672\n",
      "469 games analyzed, dataset size 32737\n",
      "470 games analyzed, dataset size 32857\n",
      "471 games analyzed, dataset size 32893\n",
      "472 games analyzed, dataset size 32952\n",
      "473 games analyzed, dataset size 33004\n",
      "474 games analyzed, dataset size 33075\n",
      "475 games analyzed, dataset size 33203\n",
      "476 games analyzed, dataset size 33262\n",
      "477 games analyzed, dataset size 33330\n",
      "478 games analyzed, dataset size 33397\n",
      "479 games analyzed, dataset size 33442\n",
      "480 games analyzed, dataset size 33529\n",
      "481 games analyzed, dataset size 33649\n",
      "482 games analyzed, dataset size 33722\n",
      "483 games analyzed, dataset size 33817\n",
      "484 games analyzed, dataset size 33885\n",
      "485 games analyzed, dataset size 33990\n",
      "486 games analyzed, dataset size 34050\n",
      "487 games analyzed, dataset size 34154\n",
      "488 games analyzed, dataset size 34224\n",
      "489 games analyzed, dataset size 34268\n",
      "490 games analyzed, dataset size 34338\n",
      "491 games analyzed, dataset size 34415\n",
      "492 games analyzed, dataset size 34509\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "494 games analyzed, dataset size 34591\n",
      "495 games analyzed, dataset size 34686\n",
      "local variable 'objective_eval' referenced before assignment\n",
      "497 games analyzed, dataset size 34733\n",
      "498 games analyzed, dataset size 34858\n",
      "499 games analyzed, dataset size 34889\n",
      "500 games analyzed, dataset size 34958\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for g in range(len(pgnGames)):\n",
    "    pgn = open(pgnGames[g])\n",
    "    \n",
    "    for k in range(500):  # 190,000 assures all games are looked at.\n",
    "        \n",
    "        try:\n",
    "            game = chess.pgn.read_game(pgn)\n",
    "\n",
    "            board_history, winrate_history = evaluate_game(game, think_time=0.025, verbose=False)\n",
    "            X += board_history\n",
    "            y += winrate_history\n",
    "            print(f\"{k+1} games analyzed, dataset size {len(X)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{e}\")\n",
    "            pass\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.dstack(X)\n",
    "y = np.array(y, dtype='float32')\n",
    "X = np.rollaxis(X, -1).reshape(-1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('test_positions.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"X\", data=X, compression='gzip', compression_opts=5)\n",
    "    hf.create_dataset(\"y\", data=y, compression='gzip', compression_opts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Model on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_kernels, v_planes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 12\n",
    "        self.value_planes = v_planes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.in_planes, self.in_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, num_kernels[0], num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, num_kernels[1], num_blocks[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, num_kernels[2], num_blocks[2], stride=1)\n",
    "        self.layer4 = self._make_layer(block, num_kernels[3], num_blocks[3], stride=1)\n",
    "\n",
    "        # value head\n",
    "        self.finalLayerValue = nn.Sequential(\n",
    "            nn.Conv2d(num_kernels[3], self.value_planes, kernel_size=1, stride=1, padding=0),  # 64, 1\n",
    "            nn.BatchNorm2d(self.value_planes),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.valueLinear = nn.Linear(64*self.value_planes*block.expansion, 1)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.finalLayerValue(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.valueLinear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetSmall():\n",
    "    return ResNet(BasicBlock, [1,1,1,2], [32,32,32,32], v_planes=2)\n",
    "\n",
    "def ResNetRegular():\n",
    "    return ResNet(BasicBlock, [3,3,3,3], [256,256,256,256], v_planes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return torch.from_numpy(bitboards_to_array(self.X[index])).float(), self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(12, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(12, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (finalLayerValue): Sequential(\n",
       "    (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (valueLinear): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNetRegular()\n",
    "model.load_state_dict(torch.load('vol_model_updated.pt', map_location=torch.device(device)))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(dataset=TrainingDataset(X, y), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 batches, 64 samples: 0.004126541782170534\n",
      "After 26 batches, 1664 samples: 0.006925160204096196\n",
      "After 51 batches, 3264 samples: 0.006851481623016298\n",
      "After 76 batches, 4864 samples: 0.0071175210522549034\n",
      "After 101 batches, 6464 samples: 0.007258291515328064\n",
      "After 126 batches, 8064 samples: 0.007254029524841508\n",
      "After 151 batches, 9664 samples: 0.0073785725980997086\n",
      "After 176 batches, 11264 samples: 0.008118359542674047\n",
      "After 201 batches, 12864 samples: 0.007749638081741385\n",
      "After 226 batches, 14464 samples: 0.007734240359313522\n",
      "After 251 batches, 16064 samples: 0.0073865170377692526\n",
      "After 276 batches, 17664 samples: 0.0076545180689182426\n",
      "After 301 batches, 19264 samples: 0.007526241586716889\n",
      "After 326 batches, 20864 samples: 0.007371178510582055\n",
      "After 351 batches, 22464 samples: 0.007434416805970101\n",
      "After 376 batches, 24064 samples: 0.007366359527564937\n",
      "After 401 batches, 25664 samples: 0.007339489261410432\n",
      "After 426 batches, 27264 samples: 0.007242688191244368\n",
      "After 451 batches, 28864 samples: 0.007381167127114531\n",
      "After 476 batches, 30464 samples: 0.0074006516938921975\n",
      "After 501 batches, 32064 samples: 0.007442924999563393\n",
      "After 526 batches, 33664 samples: 0.007446718991172151\n",
      "Mean Squared Error on Test Dataset: 0.007442758789971122\n"
     ]
    }
   ],
   "source": [
    "# Define a criterion for calculating the MSE\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to store total loss and total number of samples\n",
    "total_loss = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Iterate over the test dataset\n",
    "i = 0\n",
    "for inputs, labels in testloader:\n",
    "    # Move inputs and labels to the device (e.g., GPU) if available\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Perform forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Update total loss and total number of samples\n",
    "    total_loss += loss.item() * inputs.size(0)\n",
    "    total_samples += inputs.size(0)\n",
    "    losses += list(outputs.flatten().detach().cpu().numpy())\n",
    "    if i % 25 == 0:\n",
    "        print(f\"After {i+1} batches, {len(losses)} samples: {total_loss/total_samples}\")\n",
    "    i += 1\n",
    "\n",
    "# Calculate the average MSE\n",
    "mse = total_loss / total_samples\n",
    "\n",
    "print(\"Mean Squared Error on Test Dataset:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13946086"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.30245227"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13946086,\n",
       " 0.1293797,\n",
       " 0.12164103,\n",
       " 0.11902509,\n",
       " 0.117413275,\n",
       " 0.11166188,\n",
       " 0.110739596,\n",
       " 0.107979186,\n",
       " 0.10600522,\n",
       " 0.10273534,\n",
       " 0.102454446,\n",
       " 0.102325834,\n",
       " 0.10078408,\n",
       " 0.100346096,\n",
       " 0.0980807,\n",
       " 0.09745741,\n",
       " 0.09745294,\n",
       " 0.09677606,\n",
       " 0.096512996,\n",
       " 0.09626369,\n",
       " 0.095383435,\n",
       " 0.095316276,\n",
       " 0.09464004,\n",
       " 0.09426595,\n",
       " 0.09411624,\n",
       " 0.09321528,\n",
       " 0.0929867,\n",
       " 0.092877164,\n",
       " 0.09277512,\n",
       " 0.09271425,\n",
       " 0.09242788,\n",
       " 0.0917902,\n",
       " 0.0916804,\n",
       " 0.091618024,\n",
       " 0.09129824,\n",
       " 0.09120181,\n",
       " 0.08994926,\n",
       " 0.08944433,\n",
       " 0.089137584,\n",
       " 0.088953055,\n",
       " 0.08889559,\n",
       " 0.08838857,\n",
       " 0.08779136,\n",
       " 0.08776175,\n",
       " 0.08757596,\n",
       " 0.087187886,\n",
       " 0.08711198,\n",
       " 0.086721696,\n",
       " 0.08671602,\n",
       " 0.08627905,\n",
       " 0.08627735,\n",
       " 0.085768506,\n",
       " 0.08571564,\n",
       " 0.08567254,\n",
       " 0.08559756,\n",
       " 0.08546743,\n",
       " 0.08528513,\n",
       " 0.08496798,\n",
       " 0.084723786,\n",
       " 0.08411734,\n",
       " 0.08369338,\n",
       " 0.083686866,\n",
       " 0.08351062,\n",
       " 0.08351062,\n",
       " 0.08346775,\n",
       " 0.08342728,\n",
       " 0.083420694,\n",
       " 0.083138086,\n",
       " 0.08294839,\n",
       " 0.08257344,\n",
       " 0.082295276,\n",
       " 0.0822784,\n",
       " 0.08220789,\n",
       " 0.0822026,\n",
       " 0.08189574,\n",
       " 0.08177704,\n",
       " 0.08173679,\n",
       " 0.08136405,\n",
       " 0.08128428,\n",
       " 0.08071757,\n",
       " 0.08062433,\n",
       " 0.08056778,\n",
       " 0.0800203,\n",
       " 0.07988915,\n",
       " 0.07980102,\n",
       " 0.079768114,\n",
       " 0.07946743,\n",
       " 0.07931578,\n",
       " 0.079248056,\n",
       " 0.078851774,\n",
       " 0.078773364,\n",
       " 0.07868727,\n",
       " 0.07851824,\n",
       " 0.07848926,\n",
       " 0.0784431,\n",
       " 0.07839029,\n",
       " 0.07836393,\n",
       " 0.07829619,\n",
       " 0.07811449,\n",
       " 0.07787852,\n",
       " 0.07780334,\n",
       " 0.0777707,\n",
       " 0.0777639,\n",
       " 0.0775329,\n",
       " 0.07731087,\n",
       " 0.07725962,\n",
       " 0.07712763,\n",
       " 0.07707282,\n",
       " 0.07680576,\n",
       " 0.076803744,\n",
       " 0.076803744,\n",
       " 0.076720916,\n",
       " 0.07671176,\n",
       " 0.07660864,\n",
       " 0.076356076,\n",
       " 0.07634031,\n",
       " 0.076328,\n",
       " 0.07629813,\n",
       " 0.07620617,\n",
       " 0.07595155,\n",
       " 0.07581832,\n",
       " 0.07558942,\n",
       " 0.075425126,\n",
       " 0.075408794,\n",
       " 0.07529243,\n",
       " 0.07525036,\n",
       " 0.07524009,\n",
       " 0.07510793,\n",
       " 0.07510135,\n",
       " 0.07503697,\n",
       " 0.07499599,\n",
       " 0.0749637,\n",
       " 0.074909605,\n",
       " 0.074771196,\n",
       " 0.07449277,\n",
       " 0.07448342,\n",
       " 0.07445219,\n",
       " 0.07440945,\n",
       " 0.07429339,\n",
       " 0.07425794,\n",
       " 0.07402784,\n",
       " 0.07392226,\n",
       " 0.07389972,\n",
       " 0.073833585,\n",
       " 0.07353404,\n",
       " 0.07345099,\n",
       " 0.07337733,\n",
       " 0.073278345,\n",
       " 0.07324103,\n",
       " 0.073063135,\n",
       " 0.07305768,\n",
       " 0.07302762,\n",
       " 0.07302255,\n",
       " 0.07301599,\n",
       " 0.072985664,\n",
       " 0.072974086,\n",
       " 0.07276972,\n",
       " 0.07275675,\n",
       " 0.07272065,\n",
       " 0.072584175,\n",
       " 0.072469525,\n",
       " 0.07237106,\n",
       " 0.072326556,\n",
       " 0.07221448,\n",
       " 0.07198053,\n",
       " 0.07195925,\n",
       " 0.07183708,\n",
       " 0.07174539,\n",
       " 0.07148162,\n",
       " 0.07146495,\n",
       " 0.071392,\n",
       " 0.071358874,\n",
       " 0.07133173,\n",
       " 0.07115178,\n",
       " 0.07108575,\n",
       " 0.071085386,\n",
       " 0.07108213,\n",
       " 0.071074866,\n",
       " 0.0710149,\n",
       " 0.0709953,\n",
       " 0.070971675,\n",
       " 0.07092608,\n",
       " 0.07091831,\n",
       " 0.070893824,\n",
       " 0.07084695,\n",
       " 0.07081611,\n",
       " 0.070734575,\n",
       " 0.070713475,\n",
       " 0.070710056,\n",
       " 0.07066057,\n",
       " 0.07054521,\n",
       " 0.07053978,\n",
       " 0.07052042,\n",
       " 0.07037455,\n",
       " 0.07037382,\n",
       " 0.07012313,\n",
       " 0.07001671,\n",
       " 0.07000769,\n",
       " 0.06991508,\n",
       " 0.06986221,\n",
       " 0.06982358,\n",
       " 0.06971307,\n",
       " 0.06968003,\n",
       " 0.06967615,\n",
       " 0.069379285,\n",
       " 0.0691948,\n",
       " 0.06912319,\n",
       " 0.06908267,\n",
       " 0.06892451,\n",
       " 0.06892445,\n",
       " 0.06891028,\n",
       " 0.06887991,\n",
       " 0.06876708,\n",
       " 0.068733536,\n",
       " 0.06872859,\n",
       " 0.06869147,\n",
       " 0.06859968,\n",
       " 0.0684995,\n",
       " 0.06849604,\n",
       " 0.06845821,\n",
       " 0.068414554,\n",
       " 0.06835661,\n",
       " 0.06833951,\n",
       " 0.06820113,\n",
       " 0.06818201,\n",
       " 0.06785134,\n",
       " 0.06779294,\n",
       " 0.067684814,\n",
       " 0.067587264,\n",
       " 0.06756626,\n",
       " 0.06753507,\n",
       " 0.067465656,\n",
       " 0.067415714,\n",
       " 0.06737175,\n",
       " 0.06735323,\n",
       " 0.06735048,\n",
       " 0.06734589,\n",
       " 0.067305006,\n",
       " 0.06725448,\n",
       " 0.06719067,\n",
       " 0.06704787,\n",
       " 0.06699919,\n",
       " 0.066967435,\n",
       " 0.06695387,\n",
       " 0.06690917,\n",
       " 0.06690517,\n",
       " 0.06676749,\n",
       " 0.066754766,\n",
       " 0.06673185,\n",
       " 0.0666994,\n",
       " 0.06653455,\n",
       " 0.06652505,\n",
       " 0.06651101,\n",
       " 0.06650793,\n",
       " 0.06650392,\n",
       " 0.06611264,\n",
       " 0.06605607,\n",
       " 0.06601266,\n",
       " 0.06600413,\n",
       " 0.06591481,\n",
       " 0.0659059,\n",
       " 0.06590053,\n",
       " 0.06586834,\n",
       " 0.065861985,\n",
       " 0.06576971,\n",
       " 0.06576489,\n",
       " 0.06570661,\n",
       " 0.065674484,\n",
       " 0.06563799,\n",
       " 0.06563449,\n",
       " 0.06558742,\n",
       " 0.06557815,\n",
       " 0.06533657,\n",
       " 0.065298215,\n",
       " 0.06529038,\n",
       " 0.06528639,\n",
       " 0.065177895,\n",
       " 0.06517001,\n",
       " 0.06508833,\n",
       " 0.06508488,\n",
       " 0.06500652,\n",
       " 0.06498897,\n",
       " 0.06483159,\n",
       " 0.06479492,\n",
       " 0.06479331,\n",
       " 0.064770706,\n",
       " 0.06471699,\n",
       " 0.06470228,\n",
       " 0.06470182,\n",
       " 0.06463056,\n",
       " 0.06459373,\n",
       " 0.06454698,\n",
       " 0.06447006,\n",
       " 0.06445487,\n",
       " 0.064300895,\n",
       " 0.0642959,\n",
       " 0.064280264,\n",
       " 0.06414443,\n",
       " 0.06413236,\n",
       " 0.06412752,\n",
       " 0.064050496,\n",
       " 0.06391935,\n",
       " 0.06388602,\n",
       " 0.06379742,\n",
       " 0.0636036,\n",
       " 0.063501745,\n",
       " 0.06343453,\n",
       " 0.06340515,\n",
       " 0.063392855,\n",
       " 0.06335728,\n",
       " 0.06334059,\n",
       " 0.06331979,\n",
       " 0.063300245,\n",
       " 0.06322614,\n",
       " 0.06318954,\n",
       " 0.06318278,\n",
       " 0.06315922,\n",
       " 0.063122906,\n",
       " 0.063069075,\n",
       " 0.06306714,\n",
       " 0.06299415,\n",
       " 0.06294406,\n",
       " 0.06285041,\n",
       " 0.06280368,\n",
       " 0.06279485,\n",
       " 0.06272231,\n",
       " 0.06271536,\n",
       " 0.06260949,\n",
       " 0.06256509,\n",
       " 0.06254609,\n",
       " 0.062470872,\n",
       " 0.062429372,\n",
       " 0.06241172,\n",
       " 0.062345915,\n",
       " 0.06228854,\n",
       " 0.062271673,\n",
       " 0.062259823,\n",
       " 0.06224875,\n",
       " 0.062206797,\n",
       " 0.062202547,\n",
       " 0.062137518,\n",
       " 0.062126864,\n",
       " 0.062090516,\n",
       " 0.062053308,\n",
       " 0.062042207,\n",
       " 0.062038507,\n",
       " 0.06200329,\n",
       " 0.06194936,\n",
       " 0.061914243,\n",
       " 0.06181265,\n",
       " 0.061798,\n",
       " 0.06176038,\n",
       " 0.061699346,\n",
       " 0.061672717,\n",
       " 0.06164706,\n",
       " 0.061590396,\n",
       " 0.06157912,\n",
       " 0.061569236,\n",
       " 0.061549086,\n",
       " 0.06151281,\n",
       " 0.061434884,\n",
       " 0.061395667,\n",
       " 0.06138302,\n",
       " 0.061329275,\n",
       " 0.061316937,\n",
       " 0.061299883,\n",
       " 0.061237898,\n",
       " 0.061181366,\n",
       " 0.06108786,\n",
       " 0.061052192,\n",
       " 0.061018623,\n",
       " 0.0609763,\n",
       " 0.06092102,\n",
       " 0.060905438,\n",
       " 0.0608891,\n",
       " 0.06085392,\n",
       " 0.06079153,\n",
       " 0.060788814,\n",
       " 0.06077117,\n",
       " 0.060744435,\n",
       " 0.060732584,\n",
       " 0.060713496,\n",
       " 0.060707666,\n",
       " 0.06067388,\n",
       " 0.060633097,\n",
       " 0.060589857,\n",
       " 0.06050058,\n",
       " 0.06045776,\n",
       " 0.0604258,\n",
       " 0.060425207,\n",
       " 0.060425207,\n",
       " 0.060411938,\n",
       " 0.060374677,\n",
       " 0.060368244,\n",
       " 0.060362156,\n",
       " 0.060314383,\n",
       " 0.060271863,\n",
       " 0.060184028,\n",
       " 0.060154684,\n",
       " 0.060153782,\n",
       " 0.06012602,\n",
       " 0.060089443,\n",
       " 0.060069885,\n",
       " 0.060069554,\n",
       " 0.06006582,\n",
       " 0.06002038,\n",
       " 0.06002002,\n",
       " 0.06001962,\n",
       " 0.06000993,\n",
       " 0.059942637,\n",
       " 0.059921253,\n",
       " 0.059898414,\n",
       " 0.059844952,\n",
       " 0.05984146,\n",
       " 0.05984077,\n",
       " 0.0598399,\n",
       " 0.059834983,\n",
       " 0.059790734,\n",
       " 0.05977615,\n",
       " 0.059768524,\n",
       " 0.059767824,\n",
       " 0.05976333,\n",
       " 0.05972333,\n",
       " 0.059713304,\n",
       " 0.059706606,\n",
       " 0.059699137,\n",
       " 0.059696913,\n",
       " 0.059679344,\n",
       " 0.059655815,\n",
       " 0.059646517,\n",
       " 0.05960638,\n",
       " 0.05959755,\n",
       " 0.059487514,\n",
       " 0.059460387,\n",
       " 0.059437633,\n",
       " 0.059434835,\n",
       " 0.059410594,\n",
       " 0.059377305,\n",
       " 0.059375633,\n",
       " 0.059372555,\n",
       " 0.05933593,\n",
       " 0.059310496,\n",
       " 0.059252974,\n",
       " 0.059249777,\n",
       " 0.0592281,\n",
       " 0.05916482,\n",
       " 0.059125286,\n",
       " 0.0590035,\n",
       " 0.058991853,\n",
       " 0.058970656,\n",
       " 0.058957905,\n",
       " 0.058926117,\n",
       " 0.058898956,\n",
       " 0.05889556,\n",
       " 0.058876805,\n",
       " 0.058801893,\n",
       " 0.05879283,\n",
       " 0.05878706,\n",
       " 0.05877517,\n",
       " 0.058740765,\n",
       " 0.058727793,\n",
       " 0.05872386,\n",
       " 0.05866562,\n",
       " 0.05865374,\n",
       " 0.058611795,\n",
       " 0.05860713,\n",
       " 0.058597952,\n",
       " 0.05857603,\n",
       " 0.058530033,\n",
       " 0.058516137,\n",
       " 0.05851152,\n",
       " 0.0584335,\n",
       " 0.058410317,\n",
       " 0.05840046,\n",
       " 0.05838485,\n",
       " 0.05838412,\n",
       " 0.05836911,\n",
       " 0.05835355,\n",
       " 0.05834856,\n",
       " 0.058343217,\n",
       " 0.05831269,\n",
       " 0.058277227,\n",
       " 0.058268376,\n",
       " 0.05823183,\n",
       " 0.05821075,\n",
       " 0.05820324,\n",
       " 0.058192216,\n",
       " 0.058186945,\n",
       " 0.05818407,\n",
       " 0.05815855,\n",
       " 0.058145266,\n",
       " 0.05809682,\n",
       " 0.0580668,\n",
       " 0.05804929,\n",
       " 0.05804053,\n",
       " 0.058028486,\n",
       " 0.05800737,\n",
       " 0.05800173,\n",
       " 0.05799919,\n",
       " 0.05798104,\n",
       " 0.057947535,\n",
       " 0.057930704,\n",
       " 0.05787037,\n",
       " 0.057780962,\n",
       " 0.05773565,\n",
       " 0.057705387,\n",
       " 0.057678495,\n",
       " 0.057676636,\n",
       " 0.05763412,\n",
       " 0.057621546,\n",
       " 0.057619385,\n",
       " 0.057609864,\n",
       " 0.05759598,\n",
       " 0.057579774,\n",
       " 0.05755927,\n",
       " 0.05754595,\n",
       " 0.05753493,\n",
       " 0.057523083,\n",
       " 0.057498623,\n",
       " 0.05749353,\n",
       " 0.057476457,\n",
       " 0.05747092,\n",
       " 0.05744813,\n",
       " 0.05743942,\n",
       " 0.0574167,\n",
       " 0.057402894,\n",
       " 0.05737203,\n",
       " 0.057365596,\n",
       " 0.05735841,\n",
       " 0.05734914,\n",
       " 0.057323672,\n",
       " 0.057322264,\n",
       " 0.057319388,\n",
       " 0.057230126,\n",
       " 0.057207674,\n",
       " 0.057188347,\n",
       " 0.057186235,\n",
       " 0.057180498,\n",
       " 0.057177205,\n",
       " 0.057145864,\n",
       " 0.057122968,\n",
       " 0.057121873,\n",
       " 0.057111572,\n",
       " 0.05711144,\n",
       " 0.057109993,\n",
       " 0.05710879,\n",
       " 0.05709585,\n",
       " 0.0570812,\n",
       " 0.05705996,\n",
       " 0.057058264,\n",
       " 0.05704276,\n",
       " 0.057025142,\n",
       " 0.057021238,\n",
       " 0.05698113,\n",
       " 0.05697707,\n",
       " 0.056972094,\n",
       " 0.056955628,\n",
       " 0.056906905,\n",
       " 0.056902867,\n",
       " 0.05689825,\n",
       " 0.056895595,\n",
       " 0.056852903,\n",
       " 0.05684279,\n",
       " 0.056828495,\n",
       " 0.056761324,\n",
       " 0.056711353,\n",
       " 0.056695297,\n",
       " 0.05667337,\n",
       " 0.056621403,\n",
       " 0.056616016,\n",
       " 0.056610785,\n",
       " 0.056581806,\n",
       " 0.056555804,\n",
       " 0.056526393,\n",
       " 0.056514904,\n",
       " 0.0564887,\n",
       " 0.05645921,\n",
       " 0.056434028,\n",
       " 0.056389354,\n",
       " 0.05634035,\n",
       " 0.056323066,\n",
       " 0.05630596,\n",
       " 0.05629127,\n",
       " 0.056278855,\n",
       " 0.05624655,\n",
       " 0.05624323,\n",
       " 0.056241468,\n",
       " 0.056238268,\n",
       " 0.05622522,\n",
       " 0.056188513,\n",
       " 0.056182597,\n",
       " 0.056182265,\n",
       " 0.05615153,\n",
       " 0.05613635,\n",
       " 0.056131333,\n",
       " 0.05612872,\n",
       " 0.056110308,\n",
       " 0.056102253,\n",
       " 0.056071263,\n",
       " 0.056062754,\n",
       " 0.05601884,\n",
       " 0.056010332,\n",
       " 0.056005277,\n",
       " 0.055986684,\n",
       " 0.055971876,\n",
       " 0.055971086,\n",
       " 0.05596631,\n",
       " 0.05595835,\n",
       " 0.055937562,\n",
       " 0.055916075,\n",
       " 0.05586357,\n",
       " 0.055848856,\n",
       " 0.05584655,\n",
       " 0.055841587,\n",
       " 0.05583287,\n",
       " 0.055813853,\n",
       " 0.05580451,\n",
       " 0.05578651,\n",
       " 0.055767708,\n",
       " 0.05576631,\n",
       " 0.0557585,\n",
       " 0.055745985,\n",
       " 0.055683278,\n",
       " 0.055680938,\n",
       " 0.05567995,\n",
       " 0.055677287,\n",
       " 0.055675264,\n",
       " 0.055666767,\n",
       " 0.05566367,\n",
       " 0.055652935,\n",
       " 0.055651765,\n",
       " 0.055644076,\n",
       " 0.055623714,\n",
       " 0.055606533,\n",
       " 0.055567093,\n",
       " 0.055562764,\n",
       " 0.055562582,\n",
       " 0.055548526,\n",
       " 0.055523902,\n",
       " 0.05551547,\n",
       " 0.05549108,\n",
       " 0.05545694,\n",
       " 0.055448648,\n",
       " 0.055437125,\n",
       " 0.05541941,\n",
       " 0.055407885,\n",
       " 0.05539628,\n",
       " 0.055384003,\n",
       " 0.05535541,\n",
       " 0.055338573,\n",
       " 0.055335924,\n",
       " 0.05532437,\n",
       " 0.05529735,\n",
       " 0.055294134,\n",
       " 0.055265587,\n",
       " 0.05525645,\n",
       " 0.05525457,\n",
       " 0.055234086,\n",
       " 0.055224475,\n",
       " 0.05522241,\n",
       " 0.055184644,\n",
       " 0.05518256,\n",
       " 0.055163026,\n",
       " 0.055144686,\n",
       " 0.05514113,\n",
       " 0.055125818,\n",
       " 0.055100188,\n",
       " 0.055099484,\n",
       " 0.055074893,\n",
       " 0.055033576,\n",
       " 0.05502017,\n",
       " 0.05500781,\n",
       " 0.05500393,\n",
       " 0.054998092,\n",
       " 0.054978173,\n",
       " 0.05494985,\n",
       " 0.054943923,\n",
       " 0.05493945,\n",
       " 0.05493885,\n",
       " 0.054912835,\n",
       " 0.054892626,\n",
       " 0.05487955,\n",
       " 0.05487516,\n",
       " 0.054872267,\n",
       " 0.05481089,\n",
       " 0.054808043,\n",
       " 0.054786474,\n",
       " 0.054782867,\n",
       " 0.05478241,\n",
       " 0.054774906,\n",
       " 0.05477336,\n",
       " 0.054757006,\n",
       " 0.054726083,\n",
       " 0.054722775,\n",
       " 0.05466242,\n",
       " 0.054645352,\n",
       " 0.05460926,\n",
       " 0.054602187,\n",
       " 0.05458993,\n",
       " 0.054579977,\n",
       " 0.054559093,\n",
       " 0.054550644,\n",
       " 0.054530654,\n",
       " 0.054513477,\n",
       " 0.054486237,\n",
       " 0.05448617,\n",
       " 0.05447557,\n",
       " 0.054464817,\n",
       " 0.05446335,\n",
       " 0.054446172,\n",
       " 0.054441083,\n",
       " 0.054437067,\n",
       " 0.054386158,\n",
       " 0.054361377,\n",
       " 0.054355547,\n",
       " 0.054331023,\n",
       " 0.054285813,\n",
       " 0.05423894,\n",
       " 0.054220937,\n",
       " 0.0542199,\n",
       " 0.05421649,\n",
       " 0.05421144,\n",
       " 0.054190516,\n",
       " 0.054186713,\n",
       " 0.054183297,\n",
       " 0.054175124,\n",
       " 0.05416529,\n",
       " 0.054160897,\n",
       " 0.054148458,\n",
       " 0.054146707,\n",
       " 0.054138727,\n",
       " 0.054132514,\n",
       " 0.054116484,\n",
       " 0.054105762,\n",
       " 0.05409858,\n",
       " 0.05409067,\n",
       " 0.05408718,\n",
       " 0.054086093,\n",
       " 0.054073714,\n",
       " 0.05404339,\n",
       " 0.054041892,\n",
       " 0.054027494,\n",
       " 0.054008055,\n",
       " 0.05400363,\n",
       " 0.053985935,\n",
       " 0.053985156,\n",
       " 0.05394992,\n",
       " 0.05394538,\n",
       " 0.053941533,\n",
       " 0.05394124,\n",
       " 0.053937174,\n",
       " 0.053935707,\n",
       " 0.053933743,\n",
       " 0.053926066,\n",
       " 0.053926066,\n",
       " 0.053897243,\n",
       " 0.053882025,\n",
       " 0.05386323,\n",
       " 0.05386041,\n",
       " 0.053840462,\n",
       " 0.0538104,\n",
       " 0.05380357,\n",
       " 0.05379924,\n",
       " 0.053795412,\n",
       " 0.05376818,\n",
       " 0.05375434,\n",
       " 0.05371409,\n",
       " 0.053704288,\n",
       " 0.053692445,\n",
       " 0.053678125,\n",
       " 0.053660233,\n",
       " 0.053658303,\n",
       " 0.053651076,\n",
       " 0.053610872,\n",
       " 0.053573623,\n",
       " 0.053571586,\n",
       " 0.05356901,\n",
       " 0.053550832,\n",
       " 0.053538825,\n",
       " 0.053519137,\n",
       " 0.053499877,\n",
       " 0.053498086,\n",
       " 0.053485367,\n",
       " 0.053482614,\n",
       " 0.053476483,\n",
       " 0.05346303,\n",
       " 0.05345506,\n",
       " 0.053454086,\n",
       " 0.053442057,\n",
       " 0.05342439,\n",
       " 0.053423513,\n",
       " 0.053421862,\n",
       " 0.05336908,\n",
       " 0.053340185,\n",
       " 0.053336438,\n",
       " 0.053315613,\n",
       " 0.053297207,\n",
       " 0.05328892,\n",
       " 0.053268317,\n",
       " 0.05326727,\n",
       " 0.053253584,\n",
       " 0.053249057,\n",
       " 0.053243686,\n",
       " 0.053237867,\n",
       " 0.053216435,\n",
       " 0.053210646,\n",
       " 0.05320824,\n",
       " 0.053208057,\n",
       " 0.053201348,\n",
       " 0.05318562,\n",
       " 0.05318298,\n",
       " 0.053168148,\n",
       " 0.053168107,\n",
       " 0.05315065,\n",
       " 0.05313459,\n",
       " 0.05312294,\n",
       " 0.053117502,\n",
       " 0.05311156,\n",
       " 0.05310551,\n",
       " 0.05310067,\n",
       " 0.053083643,\n",
       " 0.053075235,\n",
       " 0.05307162,\n",
       " 0.053044546,\n",
       " 0.05303112,\n",
       " 0.053024054,\n",
       " 0.0530221,\n",
       " 0.05302042,\n",
       " 0.053013816,\n",
       " 0.05300454,\n",
       " 0.052960362,\n",
       " 0.052958265,\n",
       " 0.052950606,\n",
       " 0.052938107,\n",
       " 0.052919142,\n",
       " 0.052865613,\n",
       " 0.052862786,\n",
       " 0.05285985,\n",
       " 0.0528572,\n",
       " 0.05283937,\n",
       " 0.052835852,\n",
       " 0.05281379,\n",
       " 0.052805867,\n",
       " 0.052800186,\n",
       " 0.05278434,\n",
       " 0.052768137,\n",
       " 0.052768104,\n",
       " 0.052758932,\n",
       " 0.05275064,\n",
       " 0.052750494,\n",
       " 0.052724373,\n",
       " 0.05271222,\n",
       " 0.052651104,\n",
       " 0.052644037,\n",
       " 0.05264328,\n",
       " 0.05263989,\n",
       " 0.052639313,\n",
       " 0.05262476,\n",
       " 0.05262075,\n",
       " 0.05261113,\n",
       " 0.05260654,\n",
       " 0.052584164,\n",
       " 0.052580103,\n",
       " 0.05257424,\n",
       " 0.05256432,\n",
       " 0.05256376,\n",
       " 0.05254249,\n",
       " 0.052512515,\n",
       " 0.05251221,\n",
       " 0.05250013,\n",
       " 0.05249693,\n",
       " 0.0524887,\n",
       " 0.0524666,\n",
       " 0.052463323,\n",
       " 0.05244262,\n",
       " 0.052430205,\n",
       " 0.052428603,\n",
       " 0.052423816,\n",
       " 0.052413765,\n",
       " 0.052411996,\n",
       " 0.052393105,\n",
       " 0.052385714,\n",
       " 0.052358843,\n",
       " 0.052351814,\n",
       " 0.052338857,\n",
       " 0.052289747,\n",
       " 0.052283294,\n",
       " 0.052273504,\n",
       " 0.05227214,\n",
       " 0.052270427,\n",
       " 0.05224154,\n",
       " 0.05222882,\n",
       " 0.05222411,\n",
       " 0.05220844,\n",
       " 0.052206077,\n",
       " 0.05218236,\n",
       " 0.052170325,\n",
       " 0.052159823,\n",
       " 0.052143022,\n",
       " 0.052122757,\n",
       " 0.05211981,\n",
       " 0.052115288,\n",
       " 0.052109763,\n",
       " 0.05210658,\n",
       " 0.052106265,\n",
       " 0.052079372,\n",
       " 0.052076634,\n",
       " 0.052063335,\n",
       " 0.05205174,\n",
       " 0.052028507,\n",
       " 0.052003503,\n",
       " 0.05198121,\n",
       " 0.051973127,\n",
       " 0.05196959,\n",
       " 0.05196624,\n",
       " 0.051936537,\n",
       " 0.05193627,\n",
       " 0.051925816,\n",
       " 0.051922575,\n",
       " 0.051921707,\n",
       " 0.05192083,\n",
       " 0.051887102,\n",
       " 0.05186679,\n",
       " 0.05185542,\n",
       " 0.051846456,\n",
       " 0.051833406,\n",
       " 0.05182222,\n",
       " 0.051809266,\n",
       " 0.051793307,\n",
       " 0.051786136,\n",
       " 0.05177937,\n",
       " 0.051766153,\n",
       " 0.051756494,\n",
       " 0.051717885,\n",
       " 0.051685903,\n",
       " 0.051680304,\n",
       " 0.05166965,\n",
       " 0.05165313,\n",
       " 0.05164265,\n",
       " 0.051627714,\n",
       " 0.051622473,\n",
       " 0.05161477,\n",
       " 0.051604085,\n",
       " 0.05159673,\n",
       " 0.05159486,\n",
       " 0.05158763,\n",
       " 0.05158285,\n",
       " 0.051554576,\n",
       " 0.05154463,\n",
       " 0.05153372,\n",
       " 0.05153333,\n",
       " 0.051518146,\n",
       " 0.05148421,\n",
       " 0.051445715,\n",
       " 0.051434364,\n",
       " 0.0514245,\n",
       " 0.051401366,\n",
       " 0.051396113,\n",
       " 0.05134405,\n",
       " 0.051326238,\n",
       " 0.051306818,\n",
       " 0.051289633,\n",
       " 0.051282868,\n",
       " 0.051269967,\n",
       " 0.051260687,\n",
       " 0.051246274,\n",
       " 0.051246207,\n",
       " 0.051203303,\n",
       " 0.05119069,\n",
       " 0.05118852,\n",
       " 0.05117366,\n",
       " 0.05117001,\n",
       " 0.051162183,\n",
       " 0.051161464,\n",
       " 0.051157463,\n",
       " 0.051135227,\n",
       " 0.05113333,\n",
       " 0.051129453,\n",
       " 0.051128235,\n",
       " 0.051097617,\n",
       " 0.051080447,\n",
       " 0.051059105,\n",
       " 0.051037967,\n",
       " 0.051032383,\n",
       " 0.05102882,\n",
       " 0.05100781,\n",
       " 0.051003516,\n",
       " 0.05099816,\n",
       " 0.050978035,\n",
       " 0.050970674,\n",
       " 0.05095024,\n",
       " 0.05094865,\n",
       " 0.0509403,\n",
       " 0.050919533,\n",
       " 0.05091476,\n",
       " 0.05091193,\n",
       " 0.05090962,\n",
       " 0.050892334,\n",
       " 0.050886575,\n",
       " 0.050882157,\n",
       " ...]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(losses)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
